"""
Comprehensive Chaos Test Suite for PromptStrike
ÁõÆÊ†áÔºöÈ™åËØÅ data_corruption Âíå protocol_violation Âú∫ÊôØ‰∏ãÁ≥ªÁªüÈüßÊÄß

This suite orchestrates all chaos testing scenarios and provides comprehensive
resilience validation for the PromptStrike guardrail sidecar system.
"""

import pytest
import asyncio
import json
import time
import random
import os
import tempfile
from pathlib import Path
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass, field
from unittest.mock import patch, MagicMock, AsyncMock

from tests.chaos.chaos_replay import ChaosReplayEngine, ChaosScenario, ChaosTestResult
from tests.chaos.test_data_corruption_scenarios import DataCorruptionTester
from tests.chaos.test_protocol_violation_scenarios import ProtocolViolationTester


@dataclass
class ChaosTestSuite:
    """Comprehensive chaos test suite configuration"""
    name: str
    scenarios: List[ChaosScenario]
    duration: float
    concurrent_requests: int = 10
    chaos_intensity: float = 0.3
    target_resilience_score: float = 0.7
    recovery_timeout: float = 30.0


@dataclass
class SidecarResilienceMetrics:
    """Metrics for sidecar resilience assessment"""
    data_corruption_resilience: float = 0.0
    protocol_violation_resilience: float = 0.0
    network_partition_resilience: float = 0.0
    pod_failure_recovery_time: float = 0.0
    memory_pressure_handling: float = 0.0
    overall_resilience_score: float = 0.0
    critical_failure_count: int = 0
    graceful_degradation_score: float = 0.0
    
    def calculate_overall_score(self) -> float:
        """Calculate overall resilience score"""
        weights = {
            'data_corruption': 0.25,
            'protocol_violation': 0.25,
            'network_partition': 0.20,
            'pod_failure_recovery': 0.15,
            'memory_pressure': 0.10,
            'graceful_degradation': 0.05
        }
        
        # Normalize recovery time (lower is better)
        recovery_score = max(0, 1 - (self.pod_failure_recovery_time / 30.0))
        
        self.overall_resilience_score = (
            self.data_corruption_resilience * weights['data_corruption'] +
            self.protocol_violation_resilience * weights['protocol_violation'] +
            self.network_partition_resilience * weights['network_partition'] +
            recovery_score * weights['pod_failure_recovery'] +
            self.memory_pressure_handling * weights['memory_pressure'] +
            self.graceful_degradation_score * weights['graceful_degradation']
        )
        
        # Penalty for critical failures
        if self.critical_failure_count > 0:
            self.overall_resilience_score *= (1 - min(0.5, self.critical_failure_count * 0.1))
        
        return self.overall_resilience_score


class SidecarChaosValidator:
    """Validates sidecar resilience under comprehensive chaos scenarios"""
    
    def __init__(self):
        self.data_tester = DataCorruptionTester()
        self.protocol_tester = ProtocolViolationTester()
        self.metrics = SidecarResilienceMetrics()
        
        # Test suites for different scenarios
        self.test_suites = {
            "data_corruption": ChaosTestSuite(
                name="Data Corruption Resilience",
                scenarios=[
                    ChaosScenario.CORRUPTED_PAYLOADS,
                    ChaosScenario.GORK_DATA,
                    ChaosScenario.ENCODING_ERRORS
                ],
                duration=120.0,
                concurrent_requests=20,
                target_resilience_score=0.8
            ),
            "protocol_violation": ChaosTestSuite(
                name="Protocol Violation Resilience",
                scenarios=[
                    ChaosScenario.MALFORMED_SPANS,
                    ChaosScenario.NETWORK_PARTITION,
                    ChaosScenario.DEPENDENCY_FAILURE
                ],
                duration=90.0,
                concurrent_requests=15,
                target_resilience_score=0.75
            ),
            "infrastructure_chaos": ChaosTestSuite(
                name="Infrastructure Chaos",
                scenarios=[
                    ChaosScenario.MEMORY_PRESSURE,
                    ChaosScenario.CPU_SPIKE,
                    ChaosScenario.NETWORK_PARTITION,
                    ChaosScenario.TIMEOUT_CHAOS
                ],
                duration=180.0,
                concurrent_requests=25,
                target_resilience_score=0.7
            ),
            "combined_stress": ChaosTestSuite(
                name="Combined Stress Test",
                scenarios=[
                    ChaosScenario.CORRUPTED_PAYLOADS,
                    ChaosScenario.MALFORMED_SPANS,
                    ChaosScenario.MEMORY_PRESSURE,
                    ChaosScenario.NETWORK_PARTITION,
                    ChaosScenario.RACE_CONDITIONS
                ],
                duration=300.0,
                concurrent_requests=50,
                target_resilience_score=0.6
            )
        }
    
    async def run_comprehensive_validation(self) -> SidecarResilienceMetrics:
        """Run comprehensive chaos validation"""
        print("üéØ Starting Comprehensive Chaos Validation for PromptStrike Sidecar")
        print("=" * 80)
        
        # Run individual test suites
        await self._validate_data_corruption_resilience()
        await self._validate_protocol_violation_resilience()
        await self._validate_network_partition_resilience()
        await self._validate_pod_failure_recovery()
        await self._validate_memory_pressure_handling()
        await self._validate_graceful_degradation()
        
        # Calculate overall score
        self.metrics.calculate_overall_score()
        
        # Generate comprehensive report
        self._generate_resilience_report()
        
        return self.metrics
    
    async def _validate_data_corruption_resilience(self):
        """Validate resilience against data corruption"""
        print("\nüìä Testing Data Corruption Resilience...")
        
        suite = self.test_suites["data_corruption"]
        engine = ChaosReplayEngine(target_replay_engine=MockSidecarEngine())
        
        # Run data corruption scenarios
        result = await engine.run_chaos_test(
            test_name=suite.name,
            scenarios=suite.scenarios,
            test_duration=suite.duration,
            concurrent_requests=suite.concurrent_requests
        )
        
        # Test specific data corruption scenarios
        corruption_tests = [
            self._test_bit_flip_resilience(),
            self._test_encoding_corruption_resilience(),
            self._test_structure_corruption_resilience(),
            self._test_size_corruption_resilience()
        ]
        
        corruption_results = await asyncio.gather(*corruption_tests, return_exceptions=True)
        
        # Calculate resilience score
        base_score = result.resilience_score
        corruption_score = sum(r for r in corruption_results if isinstance(r, (int, float))) / len(corruption_results)
        
        self.metrics.data_corruption_resilience = (base_score + corruption_score) / 2
        
        print(f"‚úÖ Data Corruption Resilience: {self.metrics.data_corruption_resilience:.2f}")
    
    async def _validate_protocol_violation_resilience(self):
        """Validate resilience against protocol violations"""
        print("\nüåê Testing Protocol Violation Resilience...")
        
        suite = self.test_suites["protocol_violation"]
        engine = ChaosReplayEngine(target_replay_engine=MockSidecarEngine())
        
        # Run protocol violation scenarios
        result = await engine.run_chaos_test(
            test_name=suite.name,
            scenarios=suite.scenarios,
            test_duration=suite.duration,
            concurrent_requests=suite.concurrent_requests
        )
        
        # Test specific protocol violations
        protocol_tests = [
            self._test_http_violation_resilience(),
            self._test_json_violation_resilience(),
            self._test_websocket_violation_resilience()
        ]
        
        protocol_results = await asyncio.gather(*protocol_tests, return_exceptions=True)
        
        # Calculate resilience score
        base_score = result.resilience_score
        protocol_score = sum(r for r in protocol_results if isinstance(r, (int, float))) / len(protocol_results)
        
        self.metrics.protocol_violation_resilience = (base_score + protocol_score) / 2
        
        print(f"‚úÖ Protocol Violation Resilience: {self.metrics.protocol_violation_resilience:.2f}")
    
    async def _validate_network_partition_resilience(self):
        """Validate resilience against network partitions"""
        print("\nüîå Testing Network Partition Resilience...")
        
        # Simulate network partition scenarios
        partition_scenarios = [
            {"duration": 30, "type": "full_partition"},
            {"duration": 60, "type": "partial_partition"},
            {"duration": 10, "type": "intermittent_partition"}
        ]
        
        resilience_scores = []
        
        for scenario in partition_scenarios:
            start_time = time.time()
            
            try:
                # Simulate network partition
                await self._simulate_network_partition(scenario)
                
                # Test service recovery
                recovery_time = await self._test_service_recovery()
                
                # Calculate score based on recovery time
                max_acceptable_recovery = 30.0  # 30 seconds
                score = max(0, 1 - (recovery_time / max_acceptable_recovery))
                resilience_scores.append(score)
                
            except Exception as e:
                print(f"Network partition test failed: {e}")
                resilience_scores.append(0.0)
        
        self.metrics.network_partition_resilience = sum(resilience_scores) / len(resilience_scores)
        
        print(f"‚úÖ Network Partition Resilience: {self.metrics.network_partition_resilience:.2f}")
    
    async def _validate_pod_failure_recovery(self):
        """Validate pod failure recovery capabilities"""
        print("\nüîÑ Testing Pod Failure Recovery...")
        
        recovery_times = []
        
        # Test different pod failure scenarios
        failure_scenarios = [
            "graceful_shutdown",
            "kill_signal",
            "oom_kill",
            "disk_full",
            "container_crash"
        ]
        
        for scenario in failure_scenarios:
            start_time = time.time()
            
            try:
                # Simulate pod failure
                await self._simulate_pod_failure(scenario)
                
                # Measure recovery time
                recovery_time = await self._measure_recovery_time()
                recovery_times.append(recovery_time)
                
                if recovery_time > 60:  # More than 1 minute
                    self.metrics.critical_failure_count += 1
                
            except Exception as e:
                print(f"Pod failure test failed: {e}")
                recovery_times.append(60.0)  # Worst case
                self.metrics.critical_failure_count += 1
        
        self.metrics.pod_failure_recovery_time = sum(recovery_times) / len(recovery_times)
        
        print(f"‚úÖ Pod Failure Recovery Time: {self.metrics.pod_failure_recovery_time:.2f}s")
    
    async def _validate_memory_pressure_handling(self):
        """Validate memory pressure handling"""
        print("\nüß† Testing Memory Pressure Handling...")
        
        memory_tests = [
            {"pressure_level": 0.7, "duration": 30},  # 70% memory usage
            {"pressure_level": 0.9, "duration": 20},  # 90% memory usage
            {"pressure_level": 0.95, "duration": 10}  # 95% memory usage
        ]
        
        handling_scores = []
        
        for test in memory_tests:
            try:
                # Simulate memory pressure
                score = await self._simulate_memory_pressure(test["pressure_level"], test["duration"])
                handling_scores.append(score)
                
            except Exception as e:
                print(f"Memory pressure test failed: {e}")
                handling_scores.append(0.0)
        
        self.metrics.memory_pressure_handling = sum(handling_scores) / len(handling_scores)
        
        print(f"‚úÖ Memory Pressure Handling: {self.metrics.memory_pressure_handling:.2f}")
    
    async def _validate_graceful_degradation(self):
        """Validate graceful degradation under stress"""
        print("\nüìâ Testing Graceful Degradation...")
        
        # Test progressive load increase
        load_levels = [10, 50, 100, 200, 500, 1000]
        degradation_scores = []
        
        previous_response_time = 0
        
        for load in load_levels:
            try:
                response_time = await self._test_load_response(load)
                
                # Calculate degradation score
                if previous_response_time == 0:
                    degradation_score = 1.0
                else:
                    # Graceful degradation = response time shouldn't increase exponentially
                    increase_ratio = response_time / previous_response_time
                    degradation_score = max(0, 1 - (increase_ratio / 5.0))  # Max 5x increase acceptable
                
                degradation_scores.append(degradation_score)
                previous_response_time = response_time
                
                # Stop if system becomes unresponsive
                if response_time > 10.0:  # 10 second timeout
                    break
                
            except Exception as e:
                print(f"Load test failed at {load} requests: {e}")
                degradation_scores.append(0.0)
                break
        
        self.metrics.graceful_degradation_score = sum(degradation_scores) / len(degradation_scores)
        
        print(f"‚úÖ Graceful Degradation: {self.metrics.graceful_degradation_score:.2f}")
    
    # Helper methods for specific tests
    async def _test_bit_flip_resilience(self) -> float:
        """Test resilience against bit-flip corruption"""
        test_data = {"trace_id": "bit_flip_test", "data": "original_data"}
        corrupted_data = self.data_tester.corrupt_span_data(test_data, "bit_flip")
        
        try:
            # Simulate processing corrupted data
            await asyncio.sleep(0.01)  # Mock processing
            return 0.8  # Good resilience if no exception
        except Exception:
            return 0.3  # Partial resilience if handled gracefully
    
    async def _test_encoding_corruption_resilience(self) -> float:
        """Test resilience against encoding corruption"""
        test_data = {"trace_id": "encoding_test", "user_input": "test"}
        corrupted_data = self.data_tester.corrupt_span_data(test_data, "encoding")
        
        try:
            # Test JSON serialization
            json.dumps(corrupted_data, ensure_ascii=False)
            return 0.9
        except UnicodeDecodeError:
            return 0.6  # Handled encoding error
        except Exception:
            return 0.2  # Failed to handle
    
    async def _test_structure_corruption_resilience(self) -> float:
        """Test resilience against structural corruption"""
        test_data = {"trace_id": "structure_test"}
        corrupted_data = self.data_tester.corrupt_span_data(test_data, "structure")
        
        try:
            # Test serialization with circular references
            json.dumps(corrupted_data)
            return 0.1  # Shouldn't succeed with circular refs
        except (ValueError, RecursionError):
            return 0.8  # Good - detected circular reference
        except Exception:
            return 0.4  # Partial handling
    
    async def _test_size_corruption_resilience(self) -> float:
        """Test resilience against size corruption"""
        test_data = {"trace_id": "size_test"}
        corrupted_data = self.data_tester.corrupt_span_data(test_data, "size")
        
        start_time = time.time()
        try:
            # Test with timeout
            await asyncio.wait_for(asyncio.sleep(0.1), timeout=1.0)  # Mock processing
            processing_time = time.time() - start_time
            
            # Score based on processing time
            return max(0, 1 - (processing_time / 5.0))  # Max 5 seconds acceptable
        except asyncio.TimeoutError:
            return 0.0  # Failed to handle within timeout
        except Exception:
            return 0.3  # Partial handling
    
    async def _test_http_violation_resilience(self) -> float:
        """Test resilience against HTTP violations"""
        violation = self.protocol_tester.generate_http_violation()
        
        # Score based on violation severity and expected behavior
        severity_scores = {"low": 0.9, "medium": 0.7, "high": 0.5, "critical": 0.3}
        return severity_scores.get(violation.severity, 0.5)
    
    async def _test_json_violation_resilience(self) -> float:
        """Test resilience against JSON violations"""
        violation = self.protocol_tester.generate_json_violation()
        
        try:
            json.loads(violation.payload["body"])
            return 0.1  # Shouldn't parse malformed JSON
        except json.JSONDecodeError:
            return 0.8  # Good - detected malformed JSON
        except Exception:
            return 0.4  # Partial handling
    
    async def _test_websocket_violation_resilience(self) -> float:
        """Test resilience against WebSocket violations"""
        # Mock WebSocket violation test
        return 0.7  # Assume reasonable resilience
    
    async def _simulate_network_partition(self, scenario: Dict[str, Any]):
        """Simulate network partition"""
        # Mock network partition simulation
        await asyncio.sleep(scenario["duration"] / 10)  # Shortened for testing
    
    async def _test_service_recovery(self) -> float:
        """Test service recovery after network partition"""
        # Mock recovery test
        return random.uniform(5.0, 15.0)  # Recovery time in seconds
    
    async def _simulate_pod_failure(self, scenario: str):
        """Simulate pod failure"""
        # Mock pod failure simulation
        await asyncio.sleep(0.1)
    
    async def _measure_recovery_time(self) -> float:
        """Measure pod recovery time"""
        # Mock recovery time measurement
        return random.uniform(10.0, 30.0)
    
    async def _simulate_memory_pressure(self, pressure_level: float, duration: int) -> float:
        """Simulate memory pressure"""
        # Mock memory pressure simulation
        # Score based on pressure level (higher pressure = lower score)
        return max(0, 1 - pressure_level)
    
    async def _test_load_response(self, load: int) -> float:
        """Test response time under load"""
        # Mock load testing - response time increases with load
        base_response_time = 0.1
        load_factor = load / 100
        return base_response_time * (1 + load_factor)
    
    def _generate_resilience_report(self):
        """Generate comprehensive resilience report"""
        print("\n" + "=" * 80)
        print("üéØ COMPREHENSIVE SIDECAR RESILIENCE REPORT")
        print("=" * 80)
        
        print(f"\nüìä Overall Resilience Score: {self.metrics.overall_resilience_score:.2f}/1.0")
        
        status_icon = "üéâ" if self.metrics.overall_resilience_score >= 0.8 else \
                     "‚úÖ" if self.metrics.overall_resilience_score >= 0.7 else \
                     "‚ö†Ô∏è" if self.metrics.overall_resilience_score >= 0.5 else "‚ùå"
        
        status_text = "EXCELLENT" if self.metrics.overall_resilience_score >= 0.8 else \
                     "GOOD" if self.metrics.overall_resilience_score >= 0.7 else \
                     "ACCEPTABLE" if self.metrics.overall_resilience_score >= 0.5 else "NEEDS_IMPROVEMENT"
        
        print(f"{status_icon} Status: {status_text}")
        
        print(f"\nüìã Individual Metrics:")
        print(f"  üîß Data Corruption Resilience: {self.metrics.data_corruption_resilience:.2f}")
        print(f"  üåê Protocol Violation Resilience: {self.metrics.protocol_violation_resilience:.2f}")
        print(f"  üîå Network Partition Resilience: {self.metrics.network_partition_resilience:.2f}")
        print(f"  üîÑ Pod Failure Recovery Time: {self.metrics.pod_failure_recovery_time:.2f}s")
        print(f"  üß† Memory Pressure Handling: {self.metrics.memory_pressure_handling:.2f}")
        print(f"  üìâ Graceful Degradation: {self.metrics.graceful_degradation_score:.2f}")
        
        print(f"\nüö® Critical Failures: {self.metrics.critical_failure_count}")
        
        # Recommendations
        print(f"\nüí° Recommendations:")
        if self.metrics.data_corruption_resilience < 0.7:
            print("  ‚Ä¢ Improve data validation and corruption detection")
        if self.metrics.protocol_violation_resilience < 0.7:
            print("  ‚Ä¢ Enhance protocol validation and error handling")
        if self.metrics.network_partition_resilience < 0.7:
            print("  ‚Ä¢ Implement better network failure recovery mechanisms")
        if self.metrics.pod_failure_recovery_time > 30:
            print("  ‚Ä¢ Optimize pod restart and health check procedures")
        if self.metrics.memory_pressure_handling < 0.7:
            print("  ‚Ä¢ Implement memory management and garbage collection optimizations")
        if self.metrics.graceful_degradation_score < 0.7:
            print("  ‚Ä¢ Implement circuit breakers and load shedding mechanisms")
        
        # Final assessment
        print(f"\nüèÜ Final Assessment:")
        if self.metrics.overall_resilience_score >= 0.8:
            print("  üéâ PRODUCTION READY - Excellent resilience under chaos conditions")
        elif self.metrics.overall_resilience_score >= 0.7:
            print("  ‚úÖ PRODUCTION READY - Good resilience with minor areas for improvement")
        elif self.metrics.overall_resilience_score >= 0.5:
            print("  ‚ö†Ô∏è NEEDS IMPROVEMENT - Acceptable resilience but requires hardening")
        else:
            print("  ‚ùå NOT PRODUCTION READY - Significant resilience issues detected")


class MockSidecarEngine:
    """Mock sidecar engine for testing"""
    
    def __init__(self):
        self.healthy = True
        self.processing_count = 0
        self.error_count = 0
    
    async def replay_span(self, span_data):
        """Mock span replay"""
        self.processing_count += 1
        
        # Simulate processing time
        await asyncio.sleep(random.uniform(0.001, 0.01))
        
        # Simulate occasional errors
        if random.random() < 0.1:  # 10% error rate
            self.error_count += 1
            raise Exception("Simulated processing error")
    
    async def health_check(self):
        """Mock health check"""
        return {"status": "healthy" if self.healthy else "unhealthy"}
    
    def reset_state(self):
        """Reset mock state"""
        self.healthy = True
        self.processing_count = 0
        self.error_count = 0


@pytest.fixture
def chaos_validator():
    """Fixture for chaos validator"""
    return SidecarChaosValidator()


@pytest.mark.data_corruption
@pytest.mark.protocol_violation
@pytest.mark.asyncio
async def test_comprehensive_chaos_validation(chaos_validator):
    """Test comprehensive chaos validation suite"""
    metrics = await chaos_validator.run_comprehensive_validation()
    
    # Validate minimum resilience requirements
    assert metrics.overall_resilience_score >= 0.5, \
        f"Overall resilience score too low: {metrics.overall_resilience_score}"
    
    # Validate individual components
    assert metrics.data_corruption_resilience >= 0.4, \
        f"Data corruption resilience too low: {metrics.data_corruption_resilience}"
    
    assert metrics.protocol_violation_resilience >= 0.4, \
        f"Protocol violation resilience too low: {metrics.protocol_violation_resilience}"
    
    # Validate recovery times
    assert metrics.pod_failure_recovery_time <= 60.0, \
        f"Pod recovery time too long: {metrics.pod_failure_recovery_time}s"
    
    # Critical failures should be limited
    assert metrics.critical_failure_count <= 3, \
        f"Too many critical failures: {metrics.critical_failure_count}"


@pytest.mark.data_corruption
@pytest.mark.protocol_violation
@pytest.mark.asyncio
async def test_production_readiness_validation(chaos_validator):
    """Test production readiness under chaos"""
    metrics = await chaos_validator.run_comprehensive_validation()
    
    # Production readiness criteria
    production_criteria = {
        "overall_resilience": 0.7,
        "data_corruption": 0.6,
        "protocol_violation": 0.6,
        "network_partition": 0.6,
        "recovery_time": 45.0,
        "memory_handling": 0.6,
        "graceful_degradation": 0.5,
        "max_critical_failures": 2
    }
    
    # Check all criteria
    assert metrics.overall_resilience_score >= production_criteria["overall_resilience"]
    assert metrics.data_corruption_resilience >= production_criteria["data_corruption"]
    assert metrics.protocol_violation_resilience >= production_criteria["protocol_violation"]
    assert metrics.network_partition_resilience >= production_criteria["network_partition"]
    assert metrics.pod_failure_recovery_time <= production_criteria["recovery_time"]
    assert metrics.memory_pressure_handling >= production_criteria["memory_handling"]
    assert metrics.graceful_degradation_score >= production_criteria["graceful_degradation"]
    assert metrics.critical_failure_count <= production_criteria["max_critical_failures"]
    
    print(f"üéâ PRODUCTION READINESS VALIDATED - Overall Score: {metrics.overall_resilience_score:.2f}")


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-m", "data_corruption or protocol_violation"])